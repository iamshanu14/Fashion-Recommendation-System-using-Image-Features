{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10546061,"sourceType":"datasetVersion","datasetId":6525124}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/shanushah14/fashion-recommendation-system-using-image-features?scriptVersionId=218720879\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"A Fashion Recommendation System using Image Features leverages computer vision and machine learning techniques to analyze fashion items’ visual aspects (like colour, texture, and style) and recommend similar or complementary products to users. So, if you want to learn how to build a Fashion Recommendation System by utilizing image features","metadata":{}},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-22T08:16:24.755738Z","iopub.execute_input":"2025-01-22T08:16:24.756034Z","iopub.status.idle":"2025-01-22T08:16:24.782093Z","shell.execute_reply.started":"2025-01-22T08:16:24.756009Z","shell.execute_reply":"2025-01-22T08:16:24.781058Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Fashion Recommendation System using Image Features: Process We Can Follow\nBuilding a fashion recommendation system using image features involves several key steps, leveraging both computer vision and machine learning techniques. Below is a detailed process you can follow to build a fashion recommendation system using image features:\n1. Assemble a diverse dataset of fashion items. This dataset should include a wide variety of items with different colours, patterns, styles, and categories.\n2. Ensure all images are in a consistent format (e.g., JPEG, PNG) and resolution.\n3. Implement a preprocessing function to prepare images for feature extraction.\n4. Choose a pre-trained CNN model such as VGG16, ResNet, or InceptionV3. These models, pre-trained on large datasets like ImageNet, are capable of extracting powerful feature representations from images.\n5. Pass each image through the CNN model to extract features.\n6. Define a metric for measuring the similarity between feature vectors.\n7. Rank the dataset images based on their similarity to the input image and recommend the top N items that are most similar.\n8. Implement a final function that encapsulates the entire process from pre-processing an input image, extracting features, computing similarities, and outputting recommendations.","metadata":{}},{"cell_type":"code","source":"extraction_directory = '/kaggle/input/women-fashion-dataset/women fashion'\n\nif not os.path.exists(extraction_directory):\n    os.makedirs(extraction_directory)\n\n\nextracted_files = os.listdir(extraction_directory)\nextracted_files[:10]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T08:16:24.783181Z","iopub.execute_input":"2025-01-22T08:16:24.783509Z","iopub.status.idle":"2025-01-22T08:16:24.792173Z","shell.execute_reply.started":"2025-01-22T08:16:24.783483Z","shell.execute_reply":"2025-01-22T08:16:24.79123Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# correcting the path to include the 'women fashion' directory and listing its contents\nextraction_directory_updated = os.path.join(extraction_directory, '/kaggle/input/women-fashion-dataset/women fashion')\n\n# list the files in the updated directory\nextracted_files_updated = os.listdir(extraction_directory_updated)\nextracted_files_updated[:10], len(extracted_files_updated)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T08:16:24.793446Z","iopub.execute_input":"2025-01-22T08:16:24.793785Z","iopub.status.idle":"2025-01-22T08:16:24.809977Z","shell.execute_reply.started":"2025-01-22T08:16:24.793759Z","shell.execute_reply":"2025-01-22T08:16:24.80878Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Now, let’s have a look at the first image from the dataset:","metadata":{}},{"cell_type":"code","source":"from PIL import Image\nimport matplotlib.pyplot as plt\n\n# function to load and display an image\ndef display_image(file_path):\n    image = Image.open(file_path)\n    plt.imshow(image)\n    plt.axis('off')\n    plt.show()\n\n# display the first image to understand its characteristics\nfirst_image_path = os.path.join(extraction_directory_updated, extracted_files_updated[0])\ndisplay_image(first_image_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T08:16:24.810961Z","iopub.execute_input":"2025-01-22T08:16:24.811223Z","iopub.status.idle":"2025-01-22T08:16:24.944281Z","shell.execute_reply.started":"2025-01-22T08:16:24.811201Z","shell.execute_reply":"2025-01-22T08:16:24.943231Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Now, we will create a list of all image file paths that will be used later in extracting the features from every image in the dataset:**","metadata":{}},{"cell_type":"code","source":"import glob\n\n# directory path containing your images\nimage_directory = '/kaggle/input/women-fashion-dataset/women fashion'\n\nimage_paths_list = [file for file in glob.glob(os.path.join(image_directory, '*.*')) if file.endswith(('.jpg', '.png', '.jpeg', 'webp'))]\n\n# print the list of image file paths\nprint(image_paths_list)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T08:16:24.946403Z","iopub.execute_input":"2025-01-22T08:16:24.946741Z","iopub.status.idle":"2025-01-22T08:16:24.953899Z","shell.execute_reply.started":"2025-01-22T08:16:24.946716Z","shell.execute_reply":"2025-01-22T08:16:24.952868Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"In the above code, the **glob** module is used to generate a list of file paths for images stored in the directory. The **glob.glob** function searches for files that match a specified pattern, in this case, *.*, which matches all files within the directory. The list comprehension then filters these files to include only those with specific image file extensions (.jpg, .png, .jpeg, .webp). \n\nIt ensures that image_paths_list contains paths to only the image files, excluding any other file types that might be present in the directory.\n\nNow, we will extract features from all the fashion images:","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\nfrom tensorflow.keras.models import Model\nimport numpy as np\n\nbase_model = VGG16(weights='imagenet', include_top=False)\nmodel = Model(inputs=base_model.input, outputs=base_model.output)\n\ndef preprocess_image(img_path):\n    img = image.load_img(img_path, target_size=(224, 224))\n    img_array = image.img_to_array(img)\n    img_array_expanded = np.expand_dims(img_array, axis=0)\n    return preprocess_input(img_array_expanded)\n\ndef extract_features(model, preprocessed_img):\n    features = model.predict(preprocessed_img)\n    flattened_features = features.flatten()\n    normalized_features = flattened_features / np.linalg.norm(flattened_features)\n    return normalized_features\n\nall_features = []\nall_image_names = []\n\nfor img_path in image_paths_list:\n    preprocessed_img = preprocess_image(img_path)\n    features = extract_features(model, preprocessed_img)\n    all_features.append(features)\n    all_image_names.append(os.path.basename(img_path))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T08:16:24.955108Z","iopub.execute_input":"2025-01-22T08:16:24.955351Z","iopub.status.idle":"2025-01-22T08:17:08.592926Z","shell.execute_reply.started":"2025-01-22T08:16:24.95533Z","shell.execute_reply":"2025-01-22T08:17:08.591818Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"In the above code, a feature extraction process is implemented using the VGG16 model, a popular convolutional neural network pre-trained on the ImageNet dataset, to extract visual features from images stored in image_paths_list.\n\n**Initially, the VGG16 model is loaded without its top classification layer (include_top=False), making it suitable for feature extraction rather than classification.**\nEach image path from image_paths_list is processed through a series of steps: the image is loaded and resized to **224×224** pixels to match the VGG16 input size requirements, converted to a NumPy array, and preprocessed to fit the model’s expected input format.\n\nThe preprocessed images are then fed into the VGG16 model to extract features, which are subsequently flattened and normalized to create a consistent feature vector for each image. These feature vectors (all_features) and their corresponding image filenames (all_image_names) are stored, providing a structured dataset for the next steps in building a fashion recommendation system using image features.\n\nNow, I’ll write a function to recommend fashion images based on image features:","metadata":{}},{"cell_type":"code","source":"from scipy.spatial.distance import cosine\n\ndef recommend_fashion_items_cnn(input_image_path, all_features, all_image_names, model, top_n=5):\n    # pre-process the input image and extract features\n    preprocessed_img = preprocess_image(input_image_path)\n    input_features = extract_features(model, preprocessed_img)\n\n    # calculate similarities and find the top N similar images\n    similarities = [1 - cosine(input_features, other_feature) for other_feature in all_features]\n    similar_indices = np.argsort(similarities)[-top_n:]\n\n    # filter out the input image index from similar_indices\n    similar_indices = [idx for idx in similar_indices if idx != all_image_names.index(input_image_path)]\n\n    # display the input image\n    plt.figure(figsize=(15, 10))\n    plt.subplot(1, top_n + 1, 1)\n    plt.imshow(Image.open(input_image_path))\n    plt.title(\"Input Image\")\n    plt.axis('off')\n\n    # display similar images\n    for i, idx in enumerate(similar_indices[:top_n], start=1):\n        image_path = os.path.join('/kaggle/input/women-fashion-dataset/women fashion', all_image_names[idx])\n        plt.subplot(1, top_n + 1, i + 1)\n        plt.imshow(Image.open(image_path))\n        plt.title(f\"Recommendation {i}\")\n        plt.axis('off')\n\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T08:17:08.593953Z","iopub.execute_input":"2025-01-22T08:17:08.594537Z","iopub.status.idle":"2025-01-22T08:17:08.640652Z","shell.execute_reply.started":"2025-01-22T08:17:08.594505Z","shell.execute_reply":"2025-01-22T08:17:08.639608Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"In the above code, we defined a function recommend_fashion_items_cnn, which recommends fashion items similar to a given input image using deep learning-based feature extraction. It utilizes the VGG16 model to extract high-dimensional feature vectors from images, capturing their visual essence.\n\nFor a specified input image, the function preprocesses the image, extracts its features, and calculates the cosine similarity between this feature vector and those of other images in the dataset (all_features). It ranks these images based on similarity and selects the top N most similar images to recommend, explicitly excluding the input image from being recommended to itself by filtering out its index from the list of similar indices.\n\nIn the end, the function will visualize the input image and its recommendations by displaying them.\n\nNow, here’s how we can use this function to recommend images based on a similar fashion in the input image:","metadata":{}},{"cell_type":"code","source":"input_image_path = '/kaggle/input/women-fashion-dataset/women fashion/Anarkali suit with fitted bodice with a high neckline.jpg'\nrecommend_fashion_items_cnn(input_image_path, all_features, image_paths_list, model, top_n=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T08:17:42.001162Z","iopub.execute_input":"2025-01-22T08:17:42.001489Z","iopub.status.idle":"2025-01-22T08:17:43.071027Z","shell.execute_reply.started":"2025-01-22T08:17:42.001465Z","shell.execute_reply":"2025-01-22T08:17:43.069751Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### You need to give the path of an image as an input, and you will see similar fashion recommendations as output.","metadata":{}},{"cell_type":"markdown","source":"## Summary\n\nA Fashion Recommendation System using Image Features leverages computer vision and machine learning techniques to analyze fashion items’ visual aspects (like colour, texture, and style) and recommend similar or complementary products to users.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}